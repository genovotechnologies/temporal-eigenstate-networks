{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915bfa74",
   "metadata": {},
   "source": [
    "# Temporal Eigenstate Networks - Quickstart\n",
    "\n",
    "This notebook demonstrates how to use Temporal Eigenstate Networks (TEN) for sequence modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe63c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94523471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import TemporalEigenstateNetwork, TemporalEigenstateConfig\n",
    "from train import Trainer\n",
    "from eval import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0546b",
   "metadata": {},
   "source": [
    "## Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "config = TemporalEigenstateConfig(\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    n_layers=4,\n",
    "    d_ff=1024,\n",
    "    max_seq_len=512,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = TemporalEigenstateNetwork(config)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60a542",
   "metadata": {},
   "source": [
    "## Forward Pass Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83882978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "batch_size = 4\n",
    "seq_len = 64\n",
    "d_model = 256\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa027b",
   "metadata": {},
   "source": [
    "## Efficiency Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model, device='cpu')\n",
    "\n",
    "# Measure efficiency across different sequence lengths\n",
    "seq_lengths = [32, 64, 128, 256, 512]\n",
    "results = evaluator.measure_efficiency(\n",
    "    seq_lengths=seq_lengths,\n",
    "    batch_size=8,\n",
    "    d_model=256,\n",
    "    num_runs=5,\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(results['seq_lengths'], results['forward_time'], marker='o')\n",
    "ax1.set_xlabel('Sequence Length')\n",
    "ax1.set_ylabel('Forward Time (s)')\n",
    "ax1.set_title('Computational Efficiency')\n",
    "ax1.grid(True)\n",
    "\n",
    "if any(m > 0 for m in results['memory_usage']):\n",
    "    ax2.plot(results['seq_lengths'], results['memory_usage'], marker='o', color='orange')\n",
    "    ax2.set_xlabel('Sequence Length')\n",
    "    ax2.set_ylabel('Memory Usage (MB)')\n",
    "    ax2.set_title('Memory Efficiency')\n",
    "    ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43717e3b",
   "metadata": {},
   "source": [
    "## Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf07b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create synthetic dataset\n",
    "num_samples = 1000\n",
    "X_train = torch.randn(num_samples, 64, 256)\n",
    "y_train = torch.randn(num_samples, 64, 256)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Setup trainer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device='cpu')\n",
    "\n",
    "# Train for a few epochs\n",
    "history = trainer.fit(train_loader, epochs=3)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history['train_loss'], marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcd658",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Creating a TEN model\n",
    "- Running forward passes\n",
    "- Measuring computational efficiency\n",
    "- Training the model\n",
    "\n",
    "For more examples, see the paper and benchmarks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

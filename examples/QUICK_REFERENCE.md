# ğŸš€ TEN Google Colab Quick Reference

## One-Page Cheat Sheet for Training

---

## ğŸ¯ Quick Start (5 Steps)

1. **Open Colab** â†’ [colab.research.google.com](https://colab.research.google.com)
2. **Upload notebook** â†’ `google_colab_training.ipynb`
3. **Enable GPU** â†’ Runtime > Change runtime type > T4 GPU
4. **Run all cells** â†’ Runtime > Run all
5. **Wait ~20 min** â†’ Model trains automatically

---

## âš™ï¸ Key Configuration Settings

### Model Size (Cell 10)
```python
config = TemporalEigenstateConfig(
    d_model=256,        # Hidden dim (128/256/512)
    n_layers=4,         # Layers (2/4/6/8)
    num_eigenstates=64, # Eigenstates (32/64/128)
)
```

### Training (Cell 12)
```python
BATCH_SIZE = 16      # Reduce if OOM (8/16/32)
NUM_EPOCHS = 3       # More = better (3/5/10)
LEARNING_RATE = 3e-4 # Standard Adam LR
MAX_SEQ_LENGTH = 512 # Reduce if OOM (256/512/1024)
```

### Dataset (Cell 9)
```python
USE_SUBSET = True    # Fast experiments
SUBSET_SIZE = 5000   # Training samples (1000-25000)
```

---

## ğŸ› Quick Fixes

### Out of Memory?
```python
BATCH_SIZE = 8
MAX_SEQ_LENGTH = 256
config.d_model = 128
config.n_layers = 2
```

### No GPU?
Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save

### Import Error?
```python
!pip install -e /content/temporal-eigenstate-networks
sys.path.insert(0, '/content/temporal-eigenstate-networks/src')
```

### Slow Training?
- Check GPU: `!nvidia-smi`
- Increase batch size if memory allows
- Use smaller dataset subset

---

## ğŸ“Š Expected Results

| Model Size | Training Time | Test Acc | Memory |
|-----------|---------------|----------|---------|
| Tiny      | ~5 min/epoch  | 82-85%   | 1.5 GB  |
| Small     | ~10 min/epoch | 85-88%   | 2.5 GB  |
| Medium    | ~20 min/epoch | 88-90%   | 4.5 GB  |

---

## ğŸ”‘ Private Repo Access

1. GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens
2. Generate token with `repo` scope
3. In Colab: ğŸ”‘ icon â†’ Add secret â†’ Name: `GITHUB_TOKEN`
4. Uncomment cell in section 3.1

---

## ğŸ’¾ Save Models to Drive

```python
from google.colab import drive
drive.mount('/content/drive')
# Models auto-save to: /content/drive/MyDrive/TEN_models/
```

---

## ğŸ“ˆ Performance Tips

âœ… Start with tiny model to test setup  
âœ… Use subset for quick experiments  
âœ… Monitor GPU with `!nvidia-smi`  
âœ… Save checkpoints to Google Drive  
âœ… Keep browser tab active  

---

## ğŸ“ Model Presets

### Fast Testing
```python
d_model=64, n_layers=1, batch_size=32, subset=1000
# Time: ~2 min | Acc: ~75%
```

### Balanced (Default)
```python
d_model=256, n_layers=4, batch_size=16, subset=5000
# Time: ~20 min | Acc: ~87%
```

### High Quality
```python
d_model=512, n_layers=6, batch_size=8, subset=25000
# Time: ~2 hours | Acc: ~90%
```

---

## ğŸ” Monitoring Training

Look for:
- âœ… Loss decreasing each epoch
- âœ… Accuracy increasing
- âœ… No OOM errors
- âœ… GPU utilization ~80-100%

---

## ğŸ“ Get Help

**Error in cell X?**
- Read error message carefully
- Check troubleshooting section (end of notebook)
- Verify GPU is enabled
- Try restarting runtime

**Still stuck?**
- Open GitHub issue with full error
- Include: Colab output, config used
- Mention: GPU type, dataset size

---

## ğŸ¯ Success Checklist

- [ ] GPU enabled (Tesla T4)
- [ ] Repository cloned
- [ ] Dataset downloaded
- [ ] Model created
- [ ] Training started
- [ ] Loss decreasing
- [ ] Accuracy improving
- [ ] Benchmarks complete
- [ ] Plots generated
- [ ] Model saved

---

## ğŸ’¡ Pro Tips

1. **Experiment systematically** - Change one thing at a time
2. **Use tensorboard** - Add logging for better insights
3. **Compare models** - Train baseline for comparison
4. **Document results** - Keep notes on what works
5. **Share findings** - Contribute back to project

---

## ğŸš€ Advanced: Custom Dataset

```python
# Replace cell 7 with:
from datasets import load_dataset
dataset = load_dataset("your_dataset_name")

# Adjust tokenization in cell 9
# Adjust num_classes in cell 11
```

---

## â±ï¸ Time Budget

| Task | Time |
|------|------|
| Setup | 2 min |
| Dataset | 2 min |
| Training (3 epochs) | 20 min |
| Benchmarks | 3 min |
| **Total** | **~25 min** |

---

## ğŸ¨ Output Files

After successful run:
- `ten_imdb_model.pt` - Trained model checkpoint
- `training_curves.png` - Loss/accuracy plots
- `benchmark_results.png` - Performance charts
- `/content/drive/MyDrive/TEN_models/` - Backup on Drive

---

## ğŸ† Achievement Unlocked!

After successful training, you've:
- âœ… Trained a state-of-the-art TEN model
- âœ… Benchmarked on T4 GPU
- âœ… Generated publication-ready plots
- âœ… Saved reusable checkpoints

**Next:** Try different datasets, architectures, or contribute improvements!

---

**Quick Links:**
- Main README: `/README.md`
- Full Guide: `/examples/COLAB_GUIDE.md`
- Troubleshooting: Notebook section 11
- Examples: `/examples/` directory

---

**Version**: 1.0 | **Date**: November 2025 | **Status**: Production Ready
